В проекте используются следующие понятия из области функций потерь:

### 1. **Функция потерь (Loss Function)**

Функция потерь — это мера того, насколько предсказания модели отличаются от истинных значений. Она используется для оценки качества модели и для обновления её параметров во время обучения.

- **Пример из кода:**
  ```python
  criterion = nn.CrossEntropyLoss()
  ```
  Здесь используется `CrossEntropyLoss` из PyTorch. Эта функция потерь применяется для задач классификации, где нужно определить, к какому классу относится входной пример. Она вычисляет разницу между предсказанными вероятностями и истинными метками, помогая модели обучаться на минимизацию этой разницы.

### 2. **Кросс-энтропия (Cross-Entropy Loss)**

Кросс-энтропия измеряет различие между двумя распределениями вероятностей. В контексте задач классификации она оценивает, насколько предсказанные вероятности совпадают с истинными метками.

- **Пример из кода:**
  ```python
  outputs = model(inputs)
  loss = criterion(outputs, labels)
  ```
  В данном примере `outputs` — это вероятности, предсказанные моделью для разных классов, а `labels` — истинные метки классов. `CrossEntropyLoss` вычисляет, насколько хорошо модель предсказывает правильные классы.

### 3. **Обратное распространение ошибки (Backpropagation)**

Этот метод используется для вычисления градиентов функции потерь и обновления весов модели.

- **Пример из кода:**
  ```python
  optimizer.zero_grad()
  loss.backward()
  optimizer.step()
  ```
  Здесь `optimizer.zero_grad()` очищает старые градиенты, `loss.backward()` вычисляет новые градиенты на основе текущей функции потерь, а `optimizer.step()` обновляет веса модели.

Функция потерь помогает направлять процесс обучения, позволяя модели корректировать свои предсказания и улучшать точность.